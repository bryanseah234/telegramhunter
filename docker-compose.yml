services:
  redis:
    image: redis:7-alpine
    restart: always
    init: true
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  api:
    build: .
    restart: always
    init: true
    ports:
      - "8000:8000"
    env_file: .env
    command: uvicorn app.api.main:app --host 0.0.0.0 --port 8000 --workers 2
    depends_on:
      - redis
    environment:
      - ENV=development  # Enable dev mode for manual scan triggers
    volumes:
      - .:/app
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  worker-core:
    build: .
    restart: always
    init: true
    env_file: .env
    # Core worker handles fast tasks (discovery, broadcast, system)
    command: celery -A app.workers.celery_app worker -Q celery --loglevel=info --concurrency=4
    depends_on:
      - redis
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - .:/app

  worker-scanners:
    build: .
    restart: always
    init: true
    env_file: .env
    # Dedicated worker for OSINT gathering (github, shodan, urlscan)
    command: celery -A app.workers.celery_app worker -Q scanners --loglevel=info --concurrency=2
    depends_on:
      - redis
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - .:/app

  worker-scrape:
    build: .
    restart: always
    init: true
    env_file: .env
    # Dedicated worker for heavy chat history exfiltration
    command: celery -A app.workers.celery_app worker -Q scrape --loglevel=info --concurrency=2
    depends_on:
      - redis
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - .:/app

  beat:
    build: .
    restart: always
    init: true
    env_file: .env
    # Running Celery Beat Scheduler
    command: celery -A app.workers.celery_app beat --loglevel=info --schedule /tmp/celerybeat-schedule
    depends_on:
      - redis
      - worker-core
      - worker-scanners
      - worker-scrape
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - .:/app

  bot:
    build: .
    restart: always
    init: true
    env_file: .env
    # Running the Bot Listener
    command: python -m app.services.bot_listener
    depends_on:
      - redis
      - api
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - .:/app

volumes:
  redis_data:

